---
title: "DataAuto_task"
subtitle: "Variant 3"
author: "Evgenii Berdinskikh"
date: "`r Sys.Date()`"
output:
  word_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(flextable)
library(conflicted)
library(skimr)
library(visdat)
library(ggbeeswarm)
library(RColorBrewer)
library(ggpubr)

conflict_prefer("filter", "dplyr")
conflict_prefer("lag", "dplyr")

theme_custom <- theme_bw()+ theme(
    plot.title = element_text(size = 30, hjust = 0.5),
    plot.subtitle = element_text(size = 25, hjust = 0.5),
    strip.text = element_text(size = 20),
    axis.text = element_text(size = 20),
    axis.title = element_text(size = 25),
    legend.title = element_text(size = 25),
    legend.text = element_text(size = 20)
  )

# расчет Cramérs V
Cramers_V <- function(x, y) {
 
  x <- as.factor(x)
  y <- as.factor(y)
  tbl <- table(x, y)
  chi2 <- chisq.test(tbl)$statistic
  n <- sum(tbl)
  
  V <- sqrt(
    chi2 / (n * min(nrow(tbl) - 1, ncol(tbl) - 1) ) 
    )
  
  return(V)
  
}
```

# Чтение данных

В вашем варианте нужно использовать датасет framingham.

```{r read}

list.files("data/raw")

data <- read_csv("data/raw/framingham.csv", show_col_types = FALSE)

```


# Выведите общее описание данных

```{r description}

skim(data)

vis_miss(data)+
  theme(axis.text.x = element_text(angle = 75, hjust = 0.1))

```



# Очистка данных
## Уберите переменные, в которых пропущенных значений больше 20% или уберите субъектов со слишком большим количеством пропущенных значений. Или совместите оба варианта. Напишите обоснование, почему вы выбрали тот или иной вариант:

```{r tidy1}

data %>% 
  rowwise() %>% 
  filter(
    sum(is.na( across(everything()) )) >= 2
  ) 
               
```

**Обоснование**: наибольшее количество пропусков в переменной *glucose* - **9%**, поэтому было решено не удалять ни одну из переменных, а найти тех субьктов, для котороых есть пропуски по двум переменным и более.

## Переименуйте переменные в человекочитаемый вид (что делать с пробелами в названиях?). В соответствии с описанием данных приведите переменные к нужному типу (numeric или factor). Отсортируйте данные по возрасту по убыванию:

```{r tidy2}

data %>% 
  transmute(
    Пол = factor(male, levels = c(0, 1), labels = c("Ж", "М")), Возраст = age, Образование = factor(education), 
    Курильщик = factor(currentSmoker, levels = c(0, 1), labels = c("Нет", "Да")), 
    `Число сигарет в день` = cigsPerDay, 
    `Прием препаратов для АД` = factor(BPMeds, levels = c(0, 1), labels = c("Нет", "Да")), 
    `Перенесенный инсульт` = factor(prevalentStroke, levels = c(0, 1), labels = c("Нет", "Да")), 
    Гипертония = factor(prevalentHyp, levels = c(0, 1), labels = c("Нет", "Да")), 
    Диабет = factor(diabetes, levels = c(0, 1), labels = c("Нет", "Да")), 
    `Уровень общего холестерина` = totChol, `Систолическое АД` = sysBP, `Диастолическое АД` = diaBP, 
    `Индекс массы тела` = BMI, `Частота сердечных сокращений` = heartRate, `Уровень глюкозы` = glucose, 
    `Риск развития ИБС` = factor(TenYearCHD, levels = c(0, 1), labels = c("Нет", "Да"))
  ) %>% 
  arrange(desc(Возраст))

```



## Присвойте получившийся датасет переменной "cleaned_data":

```{r tidy3}

cleaned_data <- data %>% 
  rowwise() %>% 
  filter(
    sum(is.na( across(everything()) )) < 2
  ) %>% 
  ungroup() %>% 
    transmute(
    Пол = factor(male, levels = c(0, 1), labels = c("Ж", "М")), Возраст = age, Образование = factor(education), 
    Курильщик = factor(currentSmoker, levels = c(0, 1), labels = c("Нет", "Да")), 
    `Число сигарет в день` = cigsPerDay, 
    `Прием препаратов для АД` = factor(BPMeds, levels = c(0, 1), labels = c("Нет", "Да")), 
    `Перенесенный инсульт` = factor(prevalentStroke, levels = c(0, 1), labels = c("Нет", "Да")), 
    Гипертония = factor(prevalentHyp, levels = c(0, 1), labels = c("Нет", "Да")), 
    Диабет = factor(diabetes, levels = c(0, 1), labels = c("Нет", "Да")), 
    `Уровень общего холестерина` = totChol, `Систолическое АД` = sysBP, `Диастолическое АД` = diaBP, 
    `Индекс массы тела` = BMI, `Частота сердечных сокращений` = heartRate, `Уровень глюкозы` = glucose, 
    `Риск развития ИБС` = factor(TenYearCHD, levels = c(0, 1), labels = c("Нет", "Да"))
  ) %>% 
  arrange(desc(Возраст))

```

## Сколько осталось переменных? Сколько осталось случаев? Есть ли в данных идентичные строки?

```{r tidy4}

cat(paste("В очищенных данных осталось", ncol(cleaned_data), "переменных и", nrow(cleaned_data), "случаев, количество идентичных строк -", sum(duplicated(cleaned_data))
          ))

```

## Сколько всего переменных с пропущенными значениями в данных и сколько пропущенных точек в каждой такой переменной?

```{r tidy5}

skim(cleaned_data) %>% 
  group_by(skim_type) %>%
  filter(n_missing > 0) %>%
  ungroup() %>%
  transmute("Переменная" = skim_variable, "Количество пропущенных точек" = n_missing)

```


## Сохраните в файл outliers.csv субъектов, которые являются выбросами (например, по правилу трёх сигм) — это необязательное задание со звёздочкой;

```{r tidy6}

#За выбросы принимаем значения ниже Q1 - 1.5 × IQR и выше Q3 + 1.5 × IQR.

outliers <- cleaned_data %>% 
  mutate(across(where(is.numeric), 
                      function(x) 
                        x < quantile(x, 0.25, na.rm = TRUE) - 1.5 * IQR(x, na.rm = TRUE) | 
                        x > quantile(x, 0.75, na.rm = TRUE) + 1.5 * IQR(x, na.rm = TRUE),
                      .names = "outlier_{.col}")) %>% 
  rowwise() %>% 
  mutate(outliers = sum(c_across(starts_with("outlier_")), na.rm = TRUE)) %>% 
  ungroup() %>% 
  filter(outliers > 0) %>% 
  select(1:16)


#Файл с выбросами сохраним в папку data/docs
write_excel_csv(outliers, "data/docs/outliers.csv")

```



# Описательные статистики
## Количественные переменные

Рассчитайте для всех количественных переменных для каждой группы (TenYearCHD):
- Количество значений;
- Количество пропущенных значений;
- Среднее;
- Медиану;
- Стандартное отклонение;
- 25% квантиль и 75% квантиль;
- Интерквартильный размах;
- Минимум;
- Максимум;
- 95% ДИ для среднего - задание со звёздочкой.

```{r stat_num}

statistics <- list(
  'Количество значений' = ~ as.character( sum(!is.na(.x)) ), 
  'Количество пропущенных значений'= ~ as.character( sum(is.na(.x)) ), 
  'Среднее значение' = ~ as.character( round (mean(.x, na.rm = TRUE), 2) ),
  '95% ДИ для среднего' = ~ paste0(round (t.test(.x)[["conf.int"]][1], 2), " - ", 
                                                 round(t.test(.x)[["conf.int"]][2], 2)),
  'Стандартное отклонение' = ~ as.character( round (sd(.x, na.rm = TRUE), 2) ), 
  'Медиана (Q1-Q3)' = ~ paste0(median(.x, na.rm = TRUE), " (", quantile(.x, 0.25, na.rm = TRUE), " - ",
                               quantile(.x, 0.75, na.rm = TRUE), ")"),
  'IQR' = ~ as.character( IQR(.x, na.rm = TRUE) ), 
  'Минимум и Максимум' = ~ paste0(min(.x, na.rm = TRUE),  " - ", max(.x, na.rm = TRUE)) 
  )


cleaned_data %>% 
  group_by(`Риск развития ИБС`) %>% 
  summarise(across(where(is.numeric), statistics)) %>% 
  pivot_longer(!`Риск развития ИБС`) %>% 
  separate(name, into = c("Переменная", "Статистика"), sep = "_") %>% 
  rename(`Значение` = value) %>% 
  flextable() %>% 
  theme_box() %>% 
  merge_v(c("Риск развития ИБС", "Переменная")) %>% 
  width(j = 1, width = 2) %>% 
  width(j = 2, width = 2) %>% 
  width(j = 3, width = 3.5) %>% 
  width(j = 4, width = 2)
  
```

## Категориальные переменные

Рассчитайте для всех категориальных переменных для каждой группы (TenYearCHD):
- Абсолютное количество;
- Относительное количество внутри группы;
- 95% ДИ для доли внутри группы - задание со звёздочкой.

```{r stat_nom}




for(i in match(names(
  cleaned_data %>% select(where(is.factor) & !"Риск развития ИБС" )),
  colnames(cleaned_data))
  ) {
  
  print(
  cleaned_data %>% 
  count(`Риск развития ИБС`, cleaned_data[,i],  name = "Абсолютное количество") %>% 
  group_by(`Риск развития ИБС`) %>% 
  mutate(`Относительное количество` = paste0 (round(
      `Абсолютное количество` / sum(`Абсолютное количество`) * 100, 2), " %"), 
      across(where(is.factor), ~ fct_na_value_to_level(.x, level = "Пропущенные значения"))) %>% 
  ungroup() %>% 
  flextable() %>% 
  theme_box() %>% 
  merge_v(c("Риск развития ИБС")) %>% 
  autofit()
  ) }

```



# Визуализация
## Количественные переменные

- Для каждой количественной переменной сделайте боксплоты по группам. Расположите их либо на отдельных рисунках, либо на одном, но читаемо;
- Наложите на боксплоты beeplots - задание со звёздочкой.
- Раскрасьте боксплоты с помощью библиотеки RColorBrewer.

```{r vis_num, fig.height=20, fig.width=20}

cleaned_data %>% 
  select(where(is.numeric) | `Риск развития ИБС`) %>% 
  pivot_longer(!`Риск развития ИБС`, names_to = "Переменная", values_to = "Значение") %>% 
  filter(!is.na(Значение)) %>%  
  ggplot(aes(`Риск развития ИБС`, Значение)) +
  geom_quasirandom(colour = "springgreen3")+
  geom_boxplot(aes(fill = `Риск развития ИБС`), outliers = FALSE, color = "black", linewidth = 1, alpha = 0.7)+
  scale_fill_brewer(palette = "Pastel1", direction = -1)+
  facet_wrap( ~ Переменная, scales = "free")+
  labs(x = "", title = "Сравнение распределения количественных переменных в зависимости от риска развития ИБС")+
  theme_custom+
  theme(
    legend.position = "inside", 
    legend.justification = c(0.90, 0.15)
    )


```

## Категориальные переменные

1) Сделайте подходящие визуализации категориальных переменных. Обоснуйте, почему выбрали именно этот тип.

Для графического представления двух категориальных переменных отлично подойдет **Столбчатая диаграмма**. 
Построенные графики четко визуализирует статистические данные:
  
```{r vis_nom, fig.height=10, fig.width=20}

for(i in match(names(
  cleaned_data %>% select(where(is.factor) & !"Риск развития ИБС" )),
  colnames(cleaned_data))
  ) {
  
  print(
  cleaned_data %>% 
  rename (fill = names(cleaned_data[,i])) %>% 
  count(`Риск развития ИБС`, fill,  name = "Абсолютное количество") %>% 
  group_by(`Риск развития ИБС`) %>% 
  mutate(`Относительное количество` = 
      `Абсолютное количество` / sum(`Абсолютное количество`), 
      across(where(is.factor), ~ fct_na_value_to_level(.x, level = "Пропущенные значения"))) %>% 
  ungroup() %>% 
    ggplot(aes(x = `Риск развития ИБС`, y = `Абсолютное количество`, fill = fill)) +  
    geom_col(position = position_dodge(width = 0.9)) +
    geom_text(aes(label = paste0(round(`Относительное количество`*100, 2), "%")), 
            position = position_dodge(width = 0.9), 
            size = 7, vjust = -0.5) + 
    scale_fill_brewer(name = names(cleaned_data[,i]),
                      palette = "Pastel1",
                      labels = c("Ж" = "Женщина", "М" = "Мужчина"))+
    scale_y_continuous(n.breaks = 10) +
    labs(y = "Количество наблюдений", 
         title = paste0("Распределение категорий переменной по уровням риска ИБС"), 
         subtitle = paste0("Переменная: ", names(cleaned_data[,i])))+
    theme_custom
  )
   }



```



# Статистические оценки
## Проверка на нормальность

1) Оцените каждую переменную на соответствие нормальному распределению с помощью теста Шапиро-Уилка. Какие из переменных являются нормальными и как как вы это поняли?

Все количественные переменные в различных группах Риска развития ИБС соответствуют нормальному распределению, что подтверждено результатами теста Шапиро-Уилка. Если p-value, полученное в результате данного теста, меньше заранее установленного уровня значимости (0.05), мы отклоняем нулевую гипотезу о том, что данные ненормальны. Из-за множественных сравнений решение о нормальности распределения принималось на основании скорректированных значений p-value с использованием поправки Холма.


```{r norm1}


cleaned_data %>% 
  group_by(`Риск развития ИБС`) %>%
  summarise(across(where(is.numeric), 
                   ~ shapiro.test(.x)$p.value )) %>% 
  ungroup() %>% 
  pivot_longer(!`Риск развития ИБС`, names_to = "Переменная", values_to = "p_value") %>% 
  mutate(p_value_adjusted = p.adjust(p_value, method = "holm"), 
         Результат = ifelse(p_value_adjusted < 0.05,
                            "Нормальное распределение",
                            "Ненормальное распределение"))

```

2) Постройте для каждой количественной переменной QQ-плот. Отличаются ли выводы от теста Шапиро-Уилка? Какой метод вы бы предпочли и почему?

График квантиль-квантиль (Q-Q) используется для оценки соответствия набора данных определенному теоретическому распределению. Он сравнивает квантили наблюдаемых данных с квантилями теоретического распределения.

В большинстве случаев количественные переменные в представленных данных располагаются вдоль диагональной линии, что свидетельствует о нормальности распределения. Отклонения от диагонали в верхней и нижней части могут указывать на тяжелые хвосты распределения и наличие выбросов.

Я предпочел бы использовать оба метода — тест Шапиро-Уилка и график Q-Q. Тест дает количественную оценку, а визуализация позволяет быстро выявить возможные отклонения, что дает более полное представление о распределении данных.


```{r norm2, fig.height=30, fig.width=20}

cleaned_data %>% 
select(where(is.numeric) | `Риск развития ИБС`) %>% 
  pivot_longer(!`Риск развития ИБС`, names_to = "Переменная", values_to = "Значение") %>% 
  filter(!is.na(Значение)) %>%  
  ggqqplot(., x = "Значение", color = "Риск развития ИБС") +
  facet_grid( Переменная ~  `Риск развития ИБС`, scales = "free")+
  labs(title = "QQ-плот для количественных переменных в различных группах Риска развития ИБС", 
       x = "Теоретические значение", y = "Экспериментальные значения")+
  theme_custom+
  theme(legend.position = "top", 
        strip.text = element_text(size = 15))


```

3) Ниже напишите, какие ещё методы проверки на нормальность вы знаете и какие у них есть ограничения.

Я использовал ПО Minitab, где помимо теста Шапиро-Уилка были следующие методы:
- Критерий Андерсона-Дарлинга, который более эффективен для обнаружения ненормальности в хвостах распределения.
- Критерий Колмогорова-Смирнова, который менее чувствителен к небольшим отклонениям от нормального распределения.

Кроме того, в качестве альтернативы можно использовать график плотности. Этот метод позволяет визуально оценить форму распределения и выявить возможные отклонения от нормальности.

## Сравнение групп

Сравните группы (переменная **TenYearCHD**) по каждой переменной (как количественной, так и категориальной). Для каждой переменной выберите нужный критерий и кратко обоснуйте его выбор в комментариях.

### Количественные переменные

Для сравнения количественных переменных между группами по переменной **Риск развития ИБС** использовался двухвыборочный t-тест. Тест позволяет оценить различия средних значений между двумя независимыми группами. В данном случае, значения p-value оказались ниже уровня значимости (0.05) для всех переменных, кроме **Частоты сердечных сокращений**, что свидетельствует о наличии значимых различий между средними значениями в этих группах для большинства переменных. Учитывая множественные сравнения, окончательное решение о значимости принималось на основании скорректированных значений p-value с использованием поправки Холма.

```{r test_num}

test_tibble <- tibble()
n <- 0

for(i in match(
  names(cleaned_data %>% select(where(is.numeric))),
  colnames(cleaned_data)
  )) {

n <- n+1
 
test_tibble[n,1] <- names(cleaned_data[i])
test_tibble[n,2] <- t.test(cleaned_data[[i]] ~ `Риск развития ИБС`, data = cleaned_data)$p.value 
test_tibble[n,3] <- round(diff(t.test(cleaned_data[[i]] ~ `Риск развития ИБС`, data = cleaned_data)$estimate),2)
test_tibble[n,4] <- paste0(round (t.test(cleaned_data[[i]] ~ `Риск развития ИБС`, data = cleaned_data)$conf.int[1], 2),
                      " ... ",
                      round (t.test(cleaned_data[[i]] ~ `Риск развития ИБС`, data = cleaned_data)$conf.int[2], 2))

}


test_tibble %>% 
  transmute("Переменная" = ...1, 
            "p_value" = ...2, 
            "p_value_adjusted" = p.adjust(p_value, method = "holm"), 
            "Разница средних" = ...3, 
            "95% ДИ" = ...4) 

```


### Категориальные переменные

Для сравнения категориальных переменных между группами по переменной **Риск развития ИБС** применялась мера ассоциации — V Крамера. Эта мера подходит для оценки силы связи между номинальными переменными, так как стандартизирована и принимает значения от 0 до 1. Для оценки значимости связи использовались значения p-value, полученные при расчете критерия хи-квадрат. Окончательное решение о значимости принималось на основе скорректированных p-value с использованием поправки Холма. Для всех категориальных переменных, кроме **Частоты сердечных сокращений**, значения p-value оказались ниже уровня значимости (0.05), что свидетельствует о значимых различиях между группами.


```{r test_nom, warning=FALSE}

cramer_tibble <- tibble()

n <- 0

for(i in match(
  names(cleaned_data %>% select(where(is.factor) & !"Риск развития ИБС")),
  colnames(cleaned_data)
)) {
  
n <- n + 1
 
cramer_tibble[n,1] <- names(cleaned_data[i])
cramer_tibble[n,2] <- Cramers_V(cleaned_data$`Риск развития ИБС`, cleaned_data[[i]]) 
cramer_tibble[n,3] <- chisq.test(cleaned_data$`Риск развития ИБС`, cleaned_data[[i]])$p.value

  
}

cramer_tibble %>% 
  transmute("Переменная" = ...1, 
            "V_Крамера" = ...2, 
            "p_value" = ...3, 
            "p_value_adjusted" = p.adjust(p_value, method = "holm"))


```


# Далее идут **необязательные** дополнительные задания, которые могут принести вам дополнительные баллы в том числе в случае ошибок в предыдущих
## Корреляционный анализ

1) Создайте корреляционную матрицу с визуализацией и поправкой на множественные сравнения. Объясните, когда лучше использовать корреляционные матрицы и в чём минусы и плюсы корреляционных исследований.

```{r}



```


## Моделирование

1) Постройте регрессионную модель для переменной **TenYearCHD**. Опишите процесс построения

```{r}



```




